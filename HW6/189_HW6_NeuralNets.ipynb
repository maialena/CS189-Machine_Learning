{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Maia Rosengarten <br/>\n",
    "SID: 23572580 <br/>\n",
    "Login: cs-<br/>\n",
    "April 14, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "from scipy.stats import logistic as sig\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NP FNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(arr): # d b 1 --> (d, 1)\n",
    "    return arr.reshape((arr.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr(vec): # 1 by d --> (d, )\n",
    "    return vec.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTIL FNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAccuracies(accuracies, depths):\n",
    "    '''\n",
    "        Plots accuracies as a function od depth\n",
    "        Args:\n",
    "            costs (ndarray) - lst of costs per iteration of gradient descent\n",
    "    '''\n",
    "   \n",
    "    plt.plot(depths, accuracies)\n",
    "    plt.title(\"Prediction Evaluation Decision Tree On Census Data\")\n",
    "    plt.xlabel('max_depth')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCsv(aryPredictions, strCsvName):\n",
    "    '''\n",
    "    Writes predictions of testSet to csv file\n",
    "    Args:\n",
    "        aryPredictions (ndarray) - (nx1)-array of predictions given size n test (or valid) set\n",
    "        strCsvName (str) - name of csv file to write to\n",
    "    '''\n",
    "    with open(strCsvName + '.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in range(len(aryPredictions)):\n",
    "            writer.writerow([i, aryPredictions[i]])\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def computeCost(X, y, w, regConst):\n",
    "#     prob = sp.special.expit(np.dot(X, w))\n",
    "#     ret = 1/X.shape[0] * (regConst * np.linalg.norm(w)**2) - (vec(y).T.dot(np.log(prob + 0.000001)) + (1-vec(y)).T.dot(np.log(1 - prob + 0.000001)))\n",
    "#     return arr(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, trainX, trainY, V=None, W=None, l2=None, numHiddenLayers=800, learnRateW=0.01, learnRateV=0.01, hasDecay=True, hasDropOut=False, momentum=None, batchSize=None, numIterations=10000):\n",
    "        self.X = trainX\n",
    "        self.Y = trainY\n",
    "        self.sizeH = numHiddenLayers\n",
    "        self.learnRateW = learnRateW\n",
    "        self.learnRateV = learnRateV\n",
    "        self.hasDecay = hasDecay\n",
    "        self.hasDropOut = hasDropOut\n",
    "        self.momentum = momentum\n",
    "        self.batchSize = batchSize\n",
    "        self.numIter = numIterations\n",
    "        self.V = V \n",
    "        self.W = W\n",
    "        self.predictions = []\n",
    "        self.l2 = l2\n",
    "        if V==None and W==None:\n",
    "            self.initWeights()\n",
    "    \n",
    "    def setLearningRates(self, learnRateW, learnRateV):\n",
    "        self.learnRateW = learnRateW\n",
    "        self.learnRateV = learnRateV\n",
    "    \n",
    "    def setWeights(self, W, V):\n",
    "        self.V = V\n",
    "        self.W = W\n",
    "    \n",
    "    def setHasDecay(self, hasDecay):\n",
    "        self.hasDecay = hasDecay\n",
    "    \n",
    "    def setMomentum(self, momentum):\n",
    "        self.momentum = momentum\n",
    "    \n",
    "    def initWeights(self):\n",
    "        numFeatures = self.X.shape[1]\n",
    "#         self.V = np.random.normal(loc=0.0, scale=1/np.sqrt(numFeatures), size=(self.sizeH, numFeatures))\n",
    "#         self.W = np.random.normal(loc=0.0, scale=1/np.sqrt(self.sizeH + 1), size=(26, self.sizeH + 1))\n",
    "        self.V = np.random.normal(loc=0.0, scale=0.01, size=(self.sizeH, numFeatures))\n",
    "        self.W = np.random.normal(loc=0.0, scale=0.01, size=(26, self.sizeH + 1))\n",
    "    \n",
    "    def trainSGD(self):\n",
    "        epoch = self.X.shape[0]\n",
    "        numFeatures = self.X.shape[1]\n",
    "        for i in range(self.numIter):   \n",
    "            index = i%epoch\n",
    "            sample = vec(self.X[index])\n",
    "            y = self.Y[index]\n",
    "            i+=1\n",
    "\n",
    "            if self.hasDropOut and i%10000==0:\n",
    "                inputDropOutIndices = np.random.choice(range(0, numFeatures), size=math.ceil(0.10*numFeatures), replace=False)\n",
    "                hiddenDropOutIndices = np.random.choice(range(0, self.sizeH), size=math.ceil(0.5*self.sizeH), replace=False)\n",
    "                sample[inputDropOutIndices]=0 \n",
    "                h = np.tanh(np.dot(self.V.T, sample)) \n",
    "                h[hiddenDropOutIndices]=0\n",
    "            else:\n",
    "                h = np.tanh(np.dot(self.V.T, sample)) \n",
    "            h = np.vstack(h, np.array(1))\n",
    "            z = sp.special.expit(np.dot(self.W, vec(h)))\n",
    "            \n",
    "            grad_w = grad = np.dot(z-vec(y), h.T)\n",
    "            grad_v = self.computeGradV(index, y, z, h)\n",
    "            \n",
    "            if self.hasDecay and i%50000==0:\n",
    "                self.learnRateW = 0.001\n",
    "                self.learnRateV = 0.001\n",
    "            \n",
    "            self.W = self.W - self.learnRateW * grad_w\n",
    "            self.V = self.V - self.learnRateV * grad_v\n",
    "        return self.V, self.W\n",
    "\n",
    "\n",
    "    def trainMiniBatch(self):\n",
    "        epoch = self.X.shape[0]\n",
    "        t = 0\n",
    "        \n",
    "        while t < self.numIter:\n",
    "            if (t%20000==0):\n",
    "                print('iter ' + str(t))\n",
    "            indices = np.random.choice(range(0, epoch), size=self.batchSize, replace=True)\n",
    "            samples=self.X[indices]\n",
    "            y=self.Y[indices]\n",
    "#             i = t % epoch\n",
    "#             j = (t + self.batchSize) % epoch\n",
    "\n",
    "#             if j < i:\n",
    "#                 i = 0\n",
    "#                 j = self.batchSize\n",
    "#             samples = self.X[i:j]\n",
    "#             y = self.Y[i:j]\n",
    "  \n",
    "#             if self.hasDropOut:\n",
    "#                 inputDropOutIndices = np.random.choice(range(numFeatures), size=math.ceil(0.10*numFeatures), replace=False)\n",
    "#                 hiddenDropOutIndices = np.random.choice(range(self.sizeH), size=math.ceil(0.5*self.sizeH), replace=False) \n",
    "#                 samples[inputDropOutIndices]=0 \n",
    "#                 h = np.tanh(np.dot(self.V, samples.T)) \n",
    "#                 h[hiddenDropOutIndices]=0\n",
    "#             else:\n",
    "#                 h = np.tanh(np.dot(self.V, samples.T)) \n",
    "            \n",
    "            h = np.tanh(np.dot(self.V, samples.T)) \n",
    "            h = np.vstack((h, np.array([1]*h.shape[1])))\n",
    "            z = sp.special.expit(np.dot(self.W, h))\n",
    "        \n",
    "            if (self.l2):\n",
    "                grad_w = np.dot((z-y.T), h.T) + 2*self.l2*self.W\n",
    "                grad_v = self.computeGradVBatch(indices, y, z, h) + 2*self.l2*self.V\n",
    "            else:\n",
    "                grad_w = (z-y.T).dot(h.T)\n",
    "                grad_v = np.multiply(((z.T-y).dot(self.W)).T, 1-h**2).dot(samples)[:-1]\n",
    "                \n",
    "            if self.hasDecay and t%50000==0:\n",
    "                self.learnRateW = 0.001\n",
    "                self.learnRateV = 0.001\n",
    "                \n",
    "            self.W = self.W - (self.learnRateW * grad_w)\n",
    "            self.V = self.V - (self.learnRateV * grad_v)\n",
    "            \n",
    "            t+=self.batchSize\n",
    "        return self.V, self.W\n",
    "\n",
    "    \n",
    "    def computeGradVBatch(self, indices, y, z, h):\n",
    "        '''\n",
    "            BATCH\n",
    "                samples: (50, 785)\n",
    "                y: (50,26)\n",
    "                z: (26,50)\n",
    "                h: (801,50)\n",
    "                W: (26, 801)\n",
    "                V: (800, 785)\n",
    "                dHdL: (50,801)\n",
    "                \n",
    "                ret grad (800x785)\n",
    "        '''\n",
    "        samples = self.X[indices]\n",
    "        dLdH = np.dot((z.T-y), self.W)\n",
    "        prod = np.multiply(dLdH.T, 1-np.square(h))\n",
    "        grad = np.dot(prod, samples)[:-1]\n",
    "        return grad\n",
    "    \n",
    "    def predict(self, testX):\n",
    "        sizeData = testX.shape[0]\n",
    "#         print('sizeData ' + str(sizeData))\n",
    "        for i in range(sizeData):\n",
    "            if (i%50000==0):\n",
    "                print('iter ' + str(i))\n",
    "            h = np.tanh(np.dot(self.V, vec(self.X[i].T)))\n",
    "            h = np.vstack((h, np.array(1)))\n",
    "            z = sp.special.expit(np.dot(self.W, h))\n",
    "            prediction = np.argmax(z)\n",
    "            self.predictions.append(prediction+1)\n",
    "#         print('predictions' + str(len(self.predictions)))\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictLetters = sp.io.loadmat(\"hw6_data_dist/letters_data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x = dictLetters['train_x']\n",
    "train_y = dictLetters['train_y']\n",
    "test_x = dictLetters['test_x']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalizer = scaler.fit(train_x)\n",
    "train_x = normalizer.transform(train_x)\n",
    "test_x = normalizer.transform(test_x)\n",
    "\n",
    "combined = np.hstack((train_x, train_y))\n",
    "np.random.shuffle(combined)\n",
    "train_x = combined[:, :-1]\n",
    "train_y = combined[:, -1]\n",
    "train_x = np.hstack((train_x, np.ones(shape=(train_x.shape[0], 1))))\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=.2, random_state=42)\n",
    "one_hot_train_y = pd.get_dummies(arr(train_y)).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(train_x, one_hot_train_y, l2=0.04, numHiddenLayers=800, batchSize=50, numIterations=100000, hasDecay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n"
     ]
    }
   ],
   "source": [
    "V, W = net.trainMiniBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = net.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(predictions, train_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train acc 78% with batch 100, numiter 100,000, l2=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numIterations = 10000, decayRate is every ceil(epoch/k) *=0.8 --> 79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "    \n",
    "    \n",
    "#     def computeHiddenValues(self, indexRanSample, inputDropOutIndices=None, hiddenDropOutIndices=None):\n",
    "#         '''\n",
    "#             BATCH:\n",
    "#                 sample: 50x785\n",
    "#                 V: (800, 785)\n",
    "                \n",
    "#                 ret hidden: (801, 50)\n",
    "#             SGD:\n",
    "#                 sample: 1x785\n",
    "#                 V: (800, 785)\n",
    "                \n",
    "#                 ret hidden: (800, 1)\n",
    "#         '''\n",
    "#         sample = self.X[indexRanSample]\n",
    "#         hidden = np.tanh(np.dot(self.V, sample.T))  \n",
    "#         if self.hasDropOut:\n",
    "#             sample[inputDropOutIndices]=0 \n",
    "#             hidden[hiddenDropOutIndices]=0\n",
    "#         if (self.batchSize):\n",
    "#             hidden = np.vstack((hidden, np.array([1]*hidden.shape[1])))\n",
    "#         else:    \n",
    "#             hidden = np.vstack((vec(hidden), np.array(1)))\n",
    "#         return hidden\n",
    "\n",
    "#     def computeOutputValues(self, vectHidden):\n",
    "#         '''\n",
    "#             BATCH\n",
    "#                 self.W: (26x801)\n",
    "#                 vectHidden: (801x50)         \n",
    "#                 ret output: (26x50)\n",
    "#             SGD\n",
    "#                 self.W: (26x801)\n",
    "#                 vectHidden: (801x1)            \n",
    "#                 ret output: (26x1)\n",
    "                \n",
    "#         '''\n",
    "#         if (self.batchSize):\n",
    "#             output = sp.special.expit(np.dot(self.W, vectHidden))\n",
    "#         else:\n",
    "#             output = sp.special.expit(np.dot(self.W, vec(vectHidden)))\n",
    "#         return output\n",
    "\n",
    "\n",
    "#     def computeGradW(self, z, y, h):\n",
    "#         '''\n",
    "#             BATCH\n",
    "#                 z: (26,50)\n",
    "#                 y: (50,26)\n",
    "#                 h: (801x50)  \n",
    "#                 ret (26x801)\n",
    "            \n",
    "#             SGD\n",
    "#                 z = (26x1)\n",
    "#                 y = (26x1)\n",
    "#                 h = (801x1)\n",
    "#                 ret (26x801)\n",
    "#         '''\n",
    "#         if (self.batchSize):\n",
    "#             grad = np.dot(z-y.T, h.T)\n",
    "#         else:\n",
    "#             grad = np.dot(z-vec(y), h.T)\n",
    "#         return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [189hw]",
   "language": "python",
   "name": "Python [189hw]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
