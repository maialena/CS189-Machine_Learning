{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "from scipy.stats import logistic as sig\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle as shuffle\n",
    "from sklearn.utils import resample as resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NP FNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(arr): # d b 1 --> (d, 1)\n",
    "    return arr.reshape((arr.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr(vec): # 1 by d --> (d, )\n",
    "    return vec.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Lloyd's Method on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_mnist_data = sp.io.loadmat(\"mnist_data/images.mat\")\n",
    "points = dict_mnist_data['images']\n",
    "points.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class Point(object):\n",
    "#     '''\n",
    "#     A point in n dimensional space\n",
    "#     '''\n",
    "#     def __init__(self, coords):\n",
    "#         '''\n",
    "#         coords - A list of values, one per dimension\n",
    "#         '''\n",
    "\n",
    "#         self.coords = coords\n",
    "#         self.n = len(coords)\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return str(self.coords)\n",
    "\n",
    "\n",
    "# class Cluster:\n",
    "#     '''https://gist.github.com/iandanforth/5862470'''\n",
    "#     def __init__(points):\n",
    "#         if len(points) == 0:\n",
    "#             raise Exception(\"ERROR: empty cluster\")\n",
    "#         self.points = points\n",
    "        \n",
    "#         # The dimensionality of the points in this cluster\n",
    "#         self.n = points[0].n\n",
    "\n",
    "#         # Assert that all points are of the same dimensionality\n",
    "#         for p in points:\n",
    "#             if p.n != self.n:\n",
    "#                 raise Exception(\"ERROR: inconsistent dimensions\")\n",
    "        \n",
    "#         # Set up the initial centroid (this is usually based off one point)\n",
    "#         self.centroid = self.calculateCentroid()\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         '''\n",
    "#         String representation of this object\n",
    "#         '''\n",
    "#         return str(self.points)\n",
    "    \n",
    "    \n",
    "#     def update(self, points):\n",
    "#         '''\n",
    "#         Returns the distance between the previous centroid and the new after\n",
    "#         recalculating and storing the new centroid.\n",
    "#         Note: Initially we expect centroids to shift around a lot and then\n",
    "#         gradually settle down.\n",
    "#         '''\n",
    "#         old_centroid = self.centroid\n",
    "#         self.points = points\n",
    "#         self.centroid = self.calculateCentroid()\n",
    "#         shift = getDistance(old_centroid, self.centroid)\n",
    "#         return shift\n",
    "    \n",
    "#     def calculateCentroid(self):\n",
    "#         '''\n",
    "#         Finds a virtual center point for a group of n-dimensional points\n",
    "#         '''\n",
    "#         numPoints = len(self.points)\n",
    "#         # Get a list of all coordinates in this cluster\n",
    "#         coords = [p.coords for p in self.points]\n",
    "#         # Reformat that so all x's are together, all y'z etc.\n",
    "#         unzipped = zip(*coords)\n",
    "#         # Calculate the mean for each dimension\n",
    "#         centroid_coords = [math.fsum(dList)/numPoints for dList in unzipped]\n",
    "\n",
    "#         return Point(centroid_coords)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def kmeans(points, k, cutoff):\n",
    "\n",
    "#     # Pick out k random points to use as our initial centroids\n",
    "#     initial = random.sample(points, k)\n",
    "\n",
    "#     # Create k clusters using those centroids\n",
    "#     # Note: Cluster takes lists, so we wrap each point in a list here.\n",
    "#     clusters = [Cluster([p]) for p in initial]\n",
    "\n",
    "#     # Loop through the dataset until the clusters stabilize\n",
    "#     loopCounter = 0\n",
    "#     while True:\n",
    "#         # Create a list of lists to hold the points in each cluster\n",
    "#         lists = [[] for _ in clusters]\n",
    "#         clusterCount = len(clusters)\n",
    "\n",
    "#         # Start counting loops\n",
    "#         loopCounter += 1\n",
    "#         # For every point in the dataset ...\n",
    "#         for p in points:\n",
    "#             # Get the distance between that point and the centroid of the first\n",
    "#             # cluster.\n",
    "#             smallest_distance = getDistance(p, clusters[0].centroid)\n",
    "\n",
    "#             # Set the cluster this point belongs to\n",
    "#             clusterIndex = 0\n",
    "\n",
    "#             # For the remainder of the clusters ...\n",
    "#             for i in range(clusterCount - 1):\n",
    "#                 # calculate the distance of that point to each other cluster's\n",
    "#                 # centroid.\n",
    "#                 distance = getDistance(p, clusters[i+1].centroid)\n",
    "#                 # If it's closer to that cluster's centroid update what we\n",
    "#                 # think the smallest distance is\n",
    "#                 if distance < smallest_distance:\n",
    "#                     smallest_distance = distance\n",
    "#                     clusterIndex = i+1\n",
    "#             # After finding the cluster the smallest distance away\n",
    "#             # set the point to belong to that cluster\n",
    "#             lists[clusterIndex].append(p)\n",
    "\n",
    "#         # Set our biggest_shift to zero for this iteration\n",
    "#         biggest_shift = 0.0\n",
    "\n",
    "#         # For each cluster ...\n",
    "#         for i in range(clusterCount):\n",
    "#             # Calculate how far the centroid moved in this iteration\n",
    "#             shift = clusters[i].update(lists[i])\n",
    "#             # Keep track of the largest move from all cluster centroid updates\n",
    "#             biggest_shift = max(biggest_shift, shift)\n",
    "\n",
    "#         # If the centroids have stopped moving much, say we're done!\n",
    "#         if biggest_shift < cutoff:\n",
    "#             print(\"Converged after %s iterations\" % str(loopCounter))\n",
    "#             break\n",
    "#     return clusters\n",
    "\n",
    "# def getDistance(a, b):\n",
    "#     '''\n",
    "#     Euclidean distance between two n-dimensional points.\n",
    "#     https://en.wikipedia.org/wiki/Euclidean_distance#n_dimensions\n",
    "#     Note: This can be very slow and does not scale well\n",
    "#     '''\n",
    "#     if a.n != b.n:\n",
    "#         raise Exception(\"ERROR: non comparable points\")\n",
    "\n",
    "#     accumulatedDifference = 0.0\n",
    "#     for i in range(a.n):\n",
    "#         squareDifference = pow((a.coords[i]-b.coords[i]), 2)\n",
    "#         accumulatedDifference += squareDifference\n",
    "#     distance = math.sqrt(accumulatedDifference)\n",
    "\n",
    "#     return distance\n",
    "\n",
    "# def makeRandomPoint(n, lower, upper):\n",
    "#     '''\n",
    "#     Returns a Point object with n dimensions and values between lower and\n",
    "#     upper in each of those dimensions\n",
    "#     '''\n",
    "#     p = Point([random.uniform(lower, upper) for _ in range(n)])\n",
    "#     return p\n",
    "\n",
    "# def plotClusters(data, dimensions):\n",
    "#     '''\n",
    "#     This uses the plotly offline mode to create a local HTML file.\n",
    "#     This should open your default web browser.\n",
    "#     '''\n",
    "#     if dimensions not in [2, 3]:\n",
    "#         raise Exception(\"Plots are only available for 2 and 3 dimensional data\")\n",
    "\n",
    "#     # Convert data into plotly format.\n",
    "#     traceList = []\n",
    "#     for i, c in enumerate(data):\n",
    "#         # Get a list of x,y coordinates for the points in this cluster.\n",
    "#         cluster_data = []\n",
    "#         for point in c.points:\n",
    "#             cluster_data.append(point.coords)\n",
    "\n",
    "#         trace = {}\n",
    "#         centroid = {}\n",
    "#         if dimensions == 2:\n",
    "#             # Convert our list of x,y's into an x list and a y list.\n",
    "#             trace['x'], trace['y'] = zip(*cluster_data)\n",
    "#             trace['mode'] = 'markers'\n",
    "#             trace['marker'] = {}\n",
    "#             trace['marker']['symbol'] = i\n",
    "#             trace['marker']['size'] = 12\n",
    "#             trace['name'] = \"Cluster \" + str(i)\n",
    "#             traceList.append(Scatter(**trace))\n",
    "#             # Centroid (A trace of length 1)\n",
    "#             centroid['x'] = [c.centroid.coords[0]]\n",
    "#             centroid['y'] = [c.centroid.coords[1]]\n",
    "#             centroid['mode'] = 'markers'\n",
    "#             centroid['marker'] = {}\n",
    "#             centroid['marker']['symbol'] = i\n",
    "#             centroid['marker']['color'] = 'rgb(200,10,10)'\n",
    "#             centroid['name'] = \"Centroid \" + str(i)\n",
    "#             traceList.append(Scatter(**centroid))\n",
    "#         else:\n",
    "#             symbols = [\n",
    "#                 \"circle\",\n",
    "#                 \"square\",\n",
    "#                 \"diamond\",\n",
    "#                 \"circle-open\",\n",
    "#                 \"square-open\",\n",
    "#                 \"diamond-open\",\n",
    "#                 \"cross\", \"x\"\n",
    "#             ]\n",
    "#             symbol_count = len(symbols)\n",
    "#             if i > symbol_count:\n",
    "#                 print(\"Warning: Not enough marker symbols to go around\")\n",
    "#             # Convert our list of x,y,z's separate lists.\n",
    "#             trace['x'], trace['y'], trace['z'] = zip(*cluster_data)\n",
    "#             trace['mode'] = 'markers'\n",
    "#             trace['marker'] = {}\n",
    "#             trace['marker']['symbol'] = symbols[i]\n",
    "#             trace['marker']['size'] = 12\n",
    "#             trace['name'] = \"Cluster \" + str(i)\n",
    "#             traceList.append(Scatter3d(**trace))\n",
    "#             # Centroid (A trace of length 1)\n",
    "#             centroid['x'] = [c.centroid.coords[0]]\n",
    "#             centroid['y'] = [c.centroid.coords[1]]\n",
    "#             centroid['z'] = [c.centroid.coords[2]]\n",
    "#             centroid['mode'] = 'markers'\n",
    "#             centroid['marker'] = {}\n",
    "#             centroid['marker']['symbol'] = symbols[i]\n",
    "#             centroid['marker']['color'] = 'rgb(200,10,10)'\n",
    "#             centroid['name'] = \"Centroid \" + str(i)\n",
    "#             traceList.append(Scatter3d(**centroid))\n",
    "\n",
    "#     title = \"K-means clustering with %s clusters\" % str(len(data))\n",
    "#     plotly.offline.plot({\n",
    "#         \"data\": traceList,\n",
    "#         \"layout\": Layout(title=title)\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotly = False\n",
    "# try:\n",
    "#     import plotly\n",
    "#     from plotly.graph_objs import Scatter, Scatter3d, Layout\n",
    "# except ImportError:\n",
    "#     print(\"INFO: Plotly is not installed, plots will not be generated.\")\n",
    "\n",
    "# def main():\n",
    "\n",
    "#     # How many points are in our dataset?\n",
    "#     num_points = 60000\n",
    "\n",
    "#     # For each of those points how many dimensions do they have?\n",
    "#     # Note: Plotting will only work in two or three dimensions\n",
    "#     dimensions = (28,28)\n",
    "\n",
    "#     # Bounds for the values of those points in each dimension\n",
    "#     lower = 0\n",
    "#     upper = 60000\n",
    "\n",
    "#     # The K in k-means. How many clusters do we assume exist?\n",
    "#     num_clusters = 5\n",
    "\n",
    "#     # When do we say the optimization has 'converged' and stop updating clusters\n",
    "#     cutoff = 0.2\n",
    "\n",
    "#     # Generate some points to cluster\n",
    "# #     points = [\n",
    "# #         makeRandomPoint(dimensions, lower, upper) for i in xrange(num_points)\n",
    "# #     ]\n",
    "#     dict_mnist_data = sp.io.loadmat(\"mnist_data/images.mat\")\n",
    "#     points = dict_mnist_data['images'].T\n",
    "\n",
    "#     # Cluster those data!\n",
    "#     clusters = kmeans(points, num_clusters, cutoff)\n",
    "\n",
    "#     # Print our clusters\n",
    "#     for i, c in enumerate(clusters):\n",
    "#         for p in c.points:\n",
    "#             print(\" Cluster: \" + str(i) + \", \\t Point :\" + str(p))\n",
    "\n",
    "#     # Display clusters using plotly for 2d data\n",
    "#     if dimensions in [2, 3] and plotly:\n",
    "#         print(\"Plotting points, launching browser ...\")\n",
    "#         plotClusters(clusters, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' borrowed from http://flothesof.github.io/k-means-numpy.html '''\n",
    "\n",
    "\n",
    "\n",
    "# def move_centroids(points, closest, centroids):\n",
    "#     \"\"\"returns the new centroids assigned from the points closest to them\"\"\"\n",
    "#     return np.array([points[closest==k].mean(axis=0) for k in range(centroids.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# points.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.subplot(121)\n",
    "# plt.scatter(points.T[:, 0], points.T[:, 1])\n",
    "# centroids = initialize_centroids(points.T, 3)\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], c='r', s=100)\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.scatter(points.T[:, 0], points.T[:, 1])\n",
    "# closest = closest_centroid(points.T, centroids)\n",
    "# centroids = move_centroids(points.T, closest, centroids)\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], c='r', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.scatter(points[:, 0], points[:, 1])\n",
    "# centroids = initialize_means(points, 5)\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], c='r', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def kMeans(k, points, numIterations):\n",
    "    '''\n",
    "    Alternate between\n",
    "        (1) yj’s are fixed; update μi’s\n",
    "        (2) μi’s are fixed; update yj’s\n",
    "        Halt when step (2) changes no assignments.\n",
    "\n",
    "    Forgy method: choose k random sample points to be initial μi’s; go to (2).\n",
    "    '''\n",
    "    numPoints = points.shape[0]\n",
    "    clusters = [[] for _ in range(k)]\n",
    "    centroids = initialize_centroids(points, k)\n",
    "    centroid_matrix = np.vstack(c for c in centroids)\n",
    "    while numIterations:\n",
    "        #step 1: fix means, change points\n",
    "        for index in range(numPoints):\n",
    "            distances = []\n",
    "            point = points[index]\n",
    "            for mean in centroids:\n",
    "                diff = np.linalg.norm(point-mean)\n",
    "                distances.append(diff)\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[cluster].append(index)   \n",
    "        #step 2: fix points, change means\n",
    "        centroids = []\n",
    "        for c in clusters:\n",
    "            cluster_points = points[c]\n",
    "            new_center = np.mean(cluster_points, axis=0)\n",
    "            centroids.append(new_center)\n",
    "        print('iter ' + str(numIterations))\n",
    "        numIterations -=1\n",
    "    return clusters, centroids\n",
    "\n",
    "def visualizeCentroids(centroids):\n",
    "    plt.plot(centroids)\n",
    "    plt.show()\n",
    "\n",
    "def visualizeClusters(clusters):\n",
    "    plt.plot(clusters)\n",
    "    \n",
    "\n",
    "def initialize_centroids(points, k):\n",
    "    \"\"\"returns k centroids and their corresponding indices from the initial points\"\"\"\n",
    "    numSamples = points.shape[0]\n",
    "    rand_k_indices = np.random.randint(0, numSamples, size=k).tolist()\n",
    "    rand_k_means = points[rand_k_indices]\n",
    "    return rand_k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100\n",
      "iter 99\n",
      "iter 98\n",
      "iter 97\n",
      "iter 96\n",
      "iter 95\n",
      "iter 94\n",
      "iter 93\n",
      "iter 92\n",
      "iter 91\n",
      "iter 90\n",
      "iter 89\n",
      "iter 88\n",
      "iter 87\n",
      "iter 86\n",
      "iter 85\n",
      "iter 84\n",
      "iter 83\n",
      "iter 82\n",
      "iter 81\n",
      "iter 80\n",
      "iter 79\n",
      "iter 78\n",
      "iter 77\n",
      "iter 76\n",
      "iter 75\n",
      "iter 74\n",
      "iter 73\n",
      "iter 72\n",
      "iter 71\n",
      "iter 70\n",
      "iter 69\n",
      "iter 68\n",
      "iter 67\n",
      "iter 66\n",
      "iter 65\n",
      "iter 64\n",
      "iter 63\n",
      "iter 62\n",
      "iter 61\n",
      "iter 60\n",
      "iter 59\n",
      "iter 58\n",
      "iter 57\n",
      "iter 56\n",
      "iter 55\n",
      "iter 54\n",
      "iter 53\n",
      "iter 52\n",
      "iter 51\n",
      "iter 50\n",
      "iter 49\n",
      "iter 48\n",
      "iter 47\n",
      "iter 46\n",
      "iter 45\n",
      "iter 44\n",
      "iter 43\n",
      "iter 42\n",
      "iter 41\n",
      "iter 40\n",
      "iter 39\n",
      "iter 38\n",
      "iter 37\n",
      "iter 36\n",
      "iter 35\n",
      "iter 34\n",
      "iter 33\n",
      "iter 32\n",
      "iter 31\n",
      "iter 30\n",
      "iter 29\n",
      "iter 28\n",
      "iter 27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-bb1297335df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-99-68b8ca1607dc>\u001b[0m in \u001b[0;36mkMeans\u001b[0;34m(k, points, numIterations)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcluster_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mnew_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mcentroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iter '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2889\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = [5, 10, 20]\n",
    "np.random.shuffle(points)\n",
    "points = np.reshape(points, (784, 60000))\n",
    "clusters, centroids = kMeans(k[0], points, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [189hw]",
   "language": "python",
   "name": "Python [189hw]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
