{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Helper Function: plot_accuracy\n",
    "Purpose: Plots Accuracy of Classifier on Input Data\n",
    "Params: \n",
    "        x - list of sample_sizes\n",
    "        Y - Accuracy Scores\n",
    "        name - Name of data_set\n",
    "Return: plots accuracy, returns None\n",
    "'''\n",
    "def plot_accuracy(x, y, name):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Num_samples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Function: train_svm\n",
    "Purpose: Trains Classifier and Plot Valid Accuracy and Training Accuracy\n",
    "Params:\n",
    "    samples - list of sample_sizes\n",
    "    clf - classifier to train\n",
    "    train_set - training data set\n",
    "    train_y - training labels\n",
    "    valid_set - valid data set\n",
    "    valid_y - valid labels\n",
    "    name - name of data set\n",
    "Return: list of validation accuracies, list of training accuracies across sample sizes\n",
    "'''\n",
    "def train_svm(samples, clf, train_set, train_y, valid_set, valid_y, name):\n",
    "    valid_score, train_score = train_svm_no_plot(samples, clf, train_set, train_y, valid_set, valid_y)\n",
    "    plot_accuracy(samples, train_score, name + ' Training_Accuracy')\n",
    "    plot_accuracy(samples, valid_score, name + ' Validation_Accuracy')\n",
    "    return valid_score, train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function: train_svm_no_plot\n",
    "Purpose: Trains Classifier Without Plot, calls train_svm and plot_accuracy\n",
    "Params: \n",
    "    samples - list of sample_sizes\n",
    "    clf - classifier to train\n",
    "    train_set - training data set\n",
    "    train_y - training labels\n",
    "    valid_set - valid data set\n",
    "    valid_y - valid labels\n",
    "    name - name of data set\n",
    "Return: list of validation accuracies, list of training accuracies across sample sizes\n",
    "'''\n",
    "def train_svm_no_plot(samples, clf, train_set, train_y, valid_set, valid_y):\n",
    "    train_scores = list()\n",
    "    valid_scores = list()\n",
    "    print(\"Sample_size --> valid_score:  train_score \")\n",
    "    for sample_size in samples:\n",
    "        clf.fit(train_set[:sample_size], train_y[:sample_size])\n",
    "        train_score = clf.score(train_set, train_y)\n",
    "        train_scores.append(train_score)\n",
    "        valid_score = clf.score(valid_set, valid_y)\n",
    "        valid_scores.append(valid_score)\n",
    "        print(str(sample_size) + ' --> ' + str(valid_score) + ' : ' + str(train_score))\n",
    "    return valid_scores, train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function: split_train_and_valid_sets\n",
    "Purpose: To Split Data into Training and Valid Sets\n",
    "Param:\n",
    "    data - data_set to split\n",
    "    size - size of sample\n",
    "Return: The shape and parititoned valid data set, valid data labels, training data set, training labels\n",
    "'''\n",
    "def split_train_and_valid_sets(data, size):\n",
    "    np.random.shuffle(data)\n",
    "    shape = data.shape[0] \n",
    "    valid_set = data[:size, :-1] \n",
    "    valid_y = data[:size, -1] \n",
    "    train_set = data[size:, :-1] \n",
    "    train_y = data[size:, -1]\n",
    "    return shape, valid_set, valid_y, train_set, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train_set (50000, 784)\n",
      "mnist_valid_set (10000, 784)\n",
      "mnist_train_y (50000,)\n",
      "mnist_valid_y (10000,)\n"
     ]
    }
   ],
   "source": [
    "# -----------MNIST SET-------- #\n",
    "mnist_dict = io.loadmat('../mnist/train.mat')\n",
    "mnist_trainX = mnist_dict['trainX']\n",
    "mnist_train_set, mnist_valid_set, mnist_train_y, mnist_valid_y = train_test_split(mnist_trainX[:, :-1], mnist_trainX[:, -1], test_size=10000, random_state=42)\n",
    "print('mnist_train_set ' + str(mnist_train_set.shape))\n",
    "print('mnist_valid_set ' + str(mnist_valid_set.shape))\n",
    "print('mnist_train_y ' + str(mnist_train_y.shape))\n",
    "print('mnist_valid_y ' + str(mnist_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------CIFAR-10 SET -------- (sklearn fn)\n",
    "cifar_dict = sp.io.loadmat('../cifar/train.mat')\n",
    "cifar_trainX = cifar_dict['trainX']\n",
    "cifar_train_set, cifar_valid_set, cifar_train_y, cifar_valid_y = train_test_split(cifar_trainX[:, :-1], cifar_trainX[:, -1], test_size=5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar_train_set (45000, 3072)\n",
      "cifar_valid_set (5000, 3072)\n",
      "cifar_train_y (45000,)\n",
      "cifar_valid_y (5000,)\n"
     ]
    }
   ],
   "source": [
    "print('cifar_train_set ' + str(cifar_train_set.shape))\n",
    "print('cifar_valid_set ' + str(cifar_valid_set.shape))\n",
    "print('cifar_train_y ' + str(cifar_train_y.shape))\n",
    "print('cifar_valid_y ' + str(cifar_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------SPAM DataSet (sklearn fn)----------------\n",
    "spam_dict = sp.io.loadmat('../spam/spam_data.mat')\n",
    "spam_trainX= spam_dict['training_data']\n",
    "spam_labels = spam_dict['training_labels']\n",
    "spam_train_set, spam_valid_set, spam_train_y, spam_valid_y = train_test_split(spam_trainX, spam_labels.T, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_train_set (4137, 32)\n",
      "spam_valid_set (1035, 32)\n",
      "spam_train_y (4137, 1)\n",
      "spam_valid_y (1035, 1)\n"
     ]
    }
   ],
   "source": [
    "print('spam_train_set ' + str(spam_train_set.shape))\n",
    "print('spam_valid_set ' + str(spam_valid_set.shape))\n",
    "print('spam_train_y ' + str(spam_train_y.shape))\n",
    "print('spam_valid_y ' + str(spam_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST\n",
      "Sample_size --> valid_score:  train_score \n",
      "100 --> 0.6908 : 0.69646\n",
      "Sample_size --> valid_score:  train_score \n",
      "200 --> 0.8101 : 0.81514\n",
      "Sample_size --> valid_score:  train_score \n",
      "500 --> 0.8686 : 0.8658\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a9a909aa8af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mexperiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m valid_error, train_error = train_svm(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y,\n\u001b[0;32m---> 11\u001b[0;31m           'MNIST')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-c270764808f9>\u001b[0m in \u001b[0;36mtrain_svm\u001b[0;34m(samples, clf, train_set, train_y, valid_set, valid_y, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m '''\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mvalid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_svm_no_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Training_Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Validation_Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e98685c2db7b>\u001b[0m in \u001b[0;36mtrain_svm_no_plot\u001b[0;34m(samples, clf, train_set, train_y, valid_set, valid_y)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mvalid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maialena/anaconda/envs/189hw/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "PROBLEM 2: TRAIN CLASSIFIERS AND PLOT ACCURACY\n",
    "'''\n",
    "\n",
    "# ----------TRAIN MNIST DATA------------#\n",
    "# expect between 70-90% accuracy\n",
    "print(\"Training MNIST\")\n",
    "clf_mnist = SVC(kernel=\"linear\")\n",
    "experiments = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "valid_error, train_error = train_svm(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y,\n",
    "          'MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------TRAIN CIFAR DATA-----------#\n",
    "# expect between 25-35% accuracy\n",
    "print(\"Training CIFAR\")\n",
    "clf_cifar = SVC(kernel='linear')\n",
    "experiments = [100, 200, 500, 1000, 2000, 5000]\n",
    "valid_error, train_error = train_svm(experiments, clf_cifar, cifar_train_set, cifar_train_y, cifar_valid_set, cifar_valid_y, 'CIFAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------TRAIN SPAM DATA -------------#\n",
    "# expect between 70-90% accuracy\n",
    "print(\"Training SPAM\")\n",
    "clf_spam = SVC(kernel=\"linear\")\n",
    "experiments = [100, 200, 500, 1000, 2000, 4137]\n",
    "\n",
    "valid_error, train_error = train_svm(experiments, clf_spam, spam_train_set, spam_train_y, spam_valid_set, spam_valid_y, 'SPAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PROBLEM 3: FIND BEST C VALUE MNIST SET\n",
    "'''\n",
    "\n",
    "# ATTEMPT 1: SMALL C-VALUES\n",
    "from sklearn.svm import SVC\n",
    "C_range = [.01, .001, .0001, .00001, .000001, .0000001, .00000001, .000000001]\n",
    "experiments = [10000]\n",
    "for c in C_range:\n",
    "    clf_mnist = SVC(C=c, kernel=\"linear\")\n",
    "    scores = train_svm_no_plot(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y)\n",
    "    print('C value: ' + str(c))\n",
    "    print('valid_score ' + str(scores[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ATTEMPT 2: SMALL C-VALUES CLOSE TO 10^-6\n",
    "from sklearn.svm import SVC\n",
    "C_range = [.000002, .000003, .000004, .000005, .000006]\n",
    "experiments = [10000]\n",
    "for c in C_range:\n",
    "    clf_mnist = SVC(C=c, kernel=\"linear\")\n",
    "    scores = train_svm_no_plot(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y)\n",
    "    print('C value: ' + str(c))\n",
    "    print('valid_score ' + str(scores[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ATTEMPT 3: Larger C Values\n",
    "from sklearn.svm import SVC\n",
    "C_range = [1, 5, 10, 100]\n",
    "experiments = [10000]\n",
    "for c in C_range:\n",
    "    clf_mnist = SVC(C=c, kernel=\"linear\")\n",
    "    scores = train_svm_no_plot(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y)\n",
    "    print('C value: ' + str(c))\n",
    "    print('valid_score ' + str(scores[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ************************** PROBLEM 3: BEST C Value ********************************\n",
    "#got this from http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html #\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range, kernel=('linear', 'rbf'))\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(mnist_train_set, mnist_train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PROBLEM 4: K-FOLD\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function k_fold_split\n",
    "Purpose: Performs k-fold Cross Validation to Compute Classifier Accuracy\n",
    "Params:\n",
    "    data - training_data to fit to model\n",
    "    clf - the classifier\n",
    "    k - the number of splits\n",
    "Returns Accuracy of classifier on validation data\n",
    "    \n",
    "'''\n",
    "def k_fold_split(data, clf, k):\n",
    "    np.random.shuffle(data)\n",
    "    valid_scores = list()\n",
    "    copy_data = data[:, :]\n",
    "    for i in range(k):\n",
    "        if is_divisible_by_k(copy_data, k):\n",
    "            k_arrays = np.split(copy_data, k)\n",
    "        else:\n",
    "            divisible_data, extra_data = preprocess_data(copy_data, k)\n",
    "            k_arrays = np.split(divisible_data, k)\n",
    "            np.vstack((k_arrays[-1], extra_data)) \n",
    "        valid_set = k_arrays.pop(i)\n",
    "        valid_data = valid_set[:, :-1]\n",
    "        valid_y = valid_set[:, -1]\n",
    "        train_set = np.vstack(k_arrays)\n",
    "        train_data = train_set[:, :-1]\n",
    "        train_y = train_set[:, -1]\n",
    "        valid_scores.append(train_svm_no_plot([train_data.shape[0]], clf, train_data, train_y, valid_data, valid_y)[0])\n",
    "    valid_score = np.sum(valid_scores)/k\n",
    "    print(\"Valid Score is:\")\n",
    "    print(valid_score)\n",
    "    return valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Helper Function: preprocess_data\n",
    "Purpose: Divides data into a set of points divisible by k, and the remainder of sample points\n",
    "Param: \n",
    "    data - the data to divide into two sets\n",
    "    k - the number of splits in k-fold algorithm\n",
    "Return: a set of divisible samples and a set of extra samples, ie the remainder\n",
    "'''\n",
    "def preprocess_data(data, k):\n",
    "    remainder = data.shape[0] % k\n",
    "    extra_samples = data[-remainder:, :]\n",
    "    divisible_samples = data[:-remainder, :]\n",
    "    return divisible_samples, extra_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Helper Function: is_divisible_by_k\n",
    "Purpose: Checks if number of samples in data set is divisible by k for k-fold split\n",
    "Param:\n",
    "    data - the data fitting classifer to\n",
    "    k - the number of splits in k-fold algorithm\n",
    "Return: True or False\n",
    "'''\n",
    "def is_divisible_by_k(data, k):\n",
    "    if data.shape[0] % k == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running KFold on k = 5 #\n",
    "print(\"Running KFOLD\")\n",
    "clf_spam = SVC(C=1000)\n",
    "two_dim_label = np.array(spam_train_y)\n",
    "spam_training = np.hstack((spam_train_set, two_dim_label))\n",
    "k_fold_split(spam_training, clf_spam, 5, 'SPAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************** PROBLEM 5: KAGGLE COMPETITION ***************\n",
    "# import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------- EXPERIMENT WITH MNIST CLF HYPER-PARAMETERS ------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf_mnist = SVC(C=0.000001, kernel=\"linear\", )\n",
    "# experiments = [1000]\n",
    "# # expect between 70-90% accuracy\n",
    "# valid_error, train_error = train_svm_no_plot(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y,\n",
    "#           'MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mnist submission\n",
    "# clf_mnist = SVC(C=0.000001, kernel=\"linear\")\n",
    "# mnist_data = io.loadmat('../mnist/test.mat')['testX']\n",
    "# clf_mnist.fit(mnist_train_set, mnist_train_y)\n",
    "# predicted_labels = clf_mnist.predict(mnist_data)\n",
    "# # file = open('mnist_submission.csv', 'w')\n",
    "# # w = csv.writer(f)\n",
    "\n",
    "# with open('mnist_kaggle.csv', 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     for i in range(len(predicted_labels)):\n",
    "#         writer.writerow([i, predicted_labels[i]])\n",
    "# csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spam_data = io.loadmat('spam/spam_data.mat')\n",
    "# print(spam_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spam submission\n",
    "# spam_data = io.loadmat('spam/spam_data.mat')['testX']\n",
    "# predicted_labels = clf_spam.predict(spam_data)\n",
    "# file = open('mnist_submission.csv', 'w')\n",
    "# w = csv.writer(f)\n",
    "\n",
    "# with open('spam_sample_submission.csv', 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     for i in range(len(predicted_labels)):\n",
    "#         writer.writerow([i, predicted_labels[i]])\n",
    "# csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [189hw]",
   "language": "python",
   "name": "Python [189hw]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
